version: '3.1'

services:

  spark-master:
    image: airflow/spark-master
    build: ./images/spark-master
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_MASTER_WEBUI_PORT=8081
      - PYSPARK_PYTHON=python3
    ports:
      - "8081:8081"
      - "7077:7077"
    volumes:
      - spark-data:/bitnami
      - ./include:/usr/local/airflow/include
      - ./apps:/opt/spark-apps
      - ./data:/opt/spark-data
    networks:
      - airflow

  spark-worker:
    image: airflow/spark-worker
    build: ./images/spark-worker
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - PYSPARK_PYTHON=python3
    volumes:
      - ./include:/usr/local/airflow/include
      - spark-data:/bitnami
      - ./apps:/opt/spark-apps
      - ./data:/opt/spark-data
    depends_on:
      - spark-master
    networks:
      - airflow

  minio:
    image: airflow/minio
    build: ./images/minio
    container_name: airflow-minio
    hostname: minio
    restart: always
    volumes:
      - minio_data:/bitnami/minio/data
    ports:
      - 9000:9000
      - 9001:9001
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - airflow
  kafka:
    image: confluentinc/cp-kafka
    ports:
      - "9092:9092"
      - "19092:19092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,DOCKER_HACK://kafka:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,DOCKER_HACK:PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    command: ["sh", "-c", "/usr/bin/kafka-topics --create --bootstrap-server kafka:9092,kafka:19092 --replication-factor 1 --partitions 1 --topic my_topic || true && /etc/confluent/docker/run"]
    networks:
      - airflow
  zookeeper:
    image: zookeeper:latest
    ports:
      - "2181:2181"
    networks:
      - airflow
  scheduler:
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - airflow
  webserver:
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - airflow
  triggerer:
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - airflow
  postgres:
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - airflow

volumes:
  minio_data:
    driver: local
  spark-data: